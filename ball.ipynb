{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a3e71e4",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4411675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff653fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476569e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e92556",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([ \n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                        [0.5,0.5,0.5]) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for training and testing\n",
    "train_path = 'D://program//pytorch//sportsball/dataset/train'\n",
    "test_path = 'D://program//pytorch//sportsball/dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd8f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloade\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size = 64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size = 32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2b0e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american_football', 'baseball', 'basketball', 'billiard_ball', 'bowling_ball', 'cricket_ball', 'football', 'golf_ball', 'hockey_ball', 'hockey_puck', 'rugby_ball', 'shuttlecock', 'table_tennis_ball', 'tennis_ball', 'volleyball']\n"
     ]
    }
   ],
   "source": [
    "#category\n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6918f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b53654c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes = 15):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3,out_channels =12,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels= 12,out_channels =20,kernel_size=3,stride=1,padding=1) \n",
    "        self.relu2 = nn.ReLU() \n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels= 20,out_channels =32,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()  \n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels= 32,out_channels =64,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu4 = nn.ReLU()  \n",
    "\n",
    "\n",
    "        self.fc =nn.Linear(in_features=75 * 75* 64 ,out_features=num_classes)\n",
    "\n",
    "        #feed forward function\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "\n",
    "        output = self.conv4(output)\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "\n",
    "            #Above output will be in matrix  form (256,32,75,75)\n",
    "\n",
    "        output= output.view(-1,64*75*75)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd60ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =ConvNet(num_classes=15).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec2a0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and loss function\n",
    "\n",
    "optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a3a474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5cd4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the size of training and testing images\n",
    "\n",
    "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc6c64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7328 1841\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74acaed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0Train loss:31Train accuracy:0.13960152838427947Test accuracy:0.14774579033134166\n",
      "Epoch :1Train loss:5Train accuracy:0.17098799126637554Test accuracy:0.12167300380228137\n",
      "Epoch :2Train loss:3Train accuracy:0.1019377729257642Test accuracy:0.08962520369364475\n",
      "Epoch :3Train loss:2Train accuracy:0.10575873362445415Test accuracy:0.06844106463878327\n",
      "Epoch :4Train loss:2Train accuracy:0.12254366812227074Test accuracy:0.09397066811515481\n",
      "Epoch :5Train loss:2Train accuracy:0.11340065502183407Test accuracy:0.07224334600760456\n",
      "Epoch :6Train loss:2Train accuracy:0.1204967248908297Test accuracy:0.06626833242802825\n",
      "Epoch :7Train loss:2Train accuracy:0.14519650655021835Test accuracy:0.11461162411732755\n",
      "Epoch :8Train loss:2Train accuracy:0.18681768558951964Test accuracy:0.11841390548614883\n",
      "Epoch :9Train loss:2Train accuracy:0.26569323144104806Test accuracy:0.07332971211298207\n",
      "Epoch :10Train loss:2Train accuracy:0.36067139737991266Test accuracy:0.12927756653992395\n",
      "Epoch :11Train loss:1Train accuracy:0.43872816593886466Test accuracy:0.18142313959804454\n",
      "Epoch :12Train loss:1Train accuracy:0.5521288209606987Test accuracy:0.24660510592069526\n",
      "Epoch :13Train loss:1Train accuracy:0.6480622270742358Test accuracy:0.2487778381314503\n",
      "Epoch :14Train loss:1Train accuracy:0.7191593886462883Test accuracy:0.3068984247691472\n",
      "Epoch :15Train loss:0Train accuracy:0.7665120087336245Test accuracy:0.20369364475828355\n",
      "Epoch :16Train loss:0Train accuracy:0.8325600436681223Test accuracy:0.24551873981531777\n",
      "Epoch :17Train loss:0Train accuracy:0.8485262008733624Test accuracy:0.20858229223248234\n",
      "Epoch :18Train loss:0Train accuracy:0.878957423580786Test accuracy:0.30798479087452474\n",
      "Epoch :19Train loss:0Train accuracy:0.9058406113537117Test accuracy:0.3367734926670288\n"
     ]
    }
   ],
   "source": [
    "#model training and saving best model\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy =0.0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i , (images,labels) in enumerate (train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images= Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        optimizer.zero_grad()  #backprop accumulates gradients, and not want them in minibatches\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() #update weight and bias\n",
    "\n",
    "        train_loss += loss.cpu().data*images.size(0)    \n",
    "        _,prediction = torch.max(outputs.data,1)   \n",
    "        train_accuracy +=int(torch.sum(prediction == labels.data))\n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "\n",
    "    #evalutaion on testing dataset\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_accuracy =0.0\n",
    "    for i , (images,labels) in enumerate (test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images= Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        \n",
    "        outputs=model(images)\n",
    "        _,prediction = torch.max(outputs.data,1)   \n",
    "        test_accuracy +=int(torch.sum(prediction == labels.data))\n",
    "    test_accuracy = test_accuracy/test_count\n",
    "\n",
    "    print('Epoch :' +str(epoch)+' Train loss:'+str(int(train_loss))+' Train accuracy:'+str(train_accuracy)+' Test accuracy:'+str(test_accuracy))\n",
    "\n",
    "    #save the best model\n",
    "\n",
    "    if test_accuracy >best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394234f6",
   "metadata": {},
   "source": [
    "Inference - testing on datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "58beef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import squeezenet1_1\n",
    "import torch.functional as F\n",
    "from io import open\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47345810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'D://program//pytorch//sportsball//dataset//train'\n",
    "pred_path = 'D://program//pytorch//sportsball//dataset//pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e13f941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american_football', 'baseball', 'basketball', 'billiard_ball', 'bowling_ball', 'cricket_ball', 'football', 'golf_ball', 'hockey_ball', 'hockey_puck', 'rugby_ball', 'shuttlecock', 'table_tennis_ball', 'tennis_ball', 'volleyball']\n"
     ]
    }
   ],
   "source": [
    "#category\n",
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a6bfec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes = 15):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3,out_channels =12,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels= 12,out_channels =20,kernel_size=3,stride=1,padding=1) \n",
    "        self.relu2 = nn.ReLU() \n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels= 20,out_channels =32,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()  \n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels= 32,out_channels =64,kernel_size=3,stride=1,padding=1) \n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu4 = nn.ReLU()  \n",
    "\n",
    "\n",
    "        self.fc =nn.Linear(in_features=75 * 75* 64 ,out_features=num_classes)\n",
    "\n",
    "        #feed forward function\n",
    "\n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "\n",
    "        output = self.conv4(output)\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "\n",
    "            #Above output will be in matrix  form (256,32,75,75)\n",
    "\n",
    "        output= output.view(-1,64*75*75)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0e7f5093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc): Linear(in_features=360000, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint =torch.load('best_checkpoint.model')\n",
    "model = ConvNet(num_classes=15)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "100127d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([ \n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                      [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ae8ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction fuction\n",
    "def prediction(img_path,transformer):\n",
    "    image = Image.open(img_path)\n",
    "    image_tensor = transformer(image).float()\n",
    "    image_tensor =image_tensor.unsqueeze_(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "    input = Variable(image_tensor)\n",
    "\n",
    "    output = model(input)\n",
    "    index=output.data.numpy().argmax()\n",
    "    pred=classes[index]\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4fa840ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = glob.glob(pred_path+'/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={} #image name as key , value as prediction\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]] = prediction(i,transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b6c927a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred\\\\0 (1).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (10) - Copy.jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (10).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (100).jpg': 'football',\n",
       " 'pred\\\\0 (101).jpg': 'football',\n",
       " 'pred\\\\0 (102).jpg': 'football',\n",
       " 'pred\\\\0 (103).jpg': 'football',\n",
       " 'pred\\\\0 (104).jpg': 'football',\n",
       " 'pred\\\\0 (105).jpg': 'football',\n",
       " 'pred\\\\0 (106).jpg': 'football',\n",
       " 'pred\\\\0 (107).jpg': 'football',\n",
       " 'pred\\\\0 (108).jpg': 'football',\n",
       " 'pred\\\\0 (109).jpg': 'volleyball',\n",
       " 'pred\\\\0 (11) - Copy.jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (11).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (110).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (111).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (112).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (113).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (114).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (115).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (116).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (117).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (118).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (119).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (12).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (120).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (121).jpg': 'tennis_ball',\n",
       " 'pred\\\\0 (122).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (123).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (124).jpg': 'golf_ball',\n",
       " 'pred\\\\0 (125).jpg': 'hockey_ball',\n",
       " 'pred\\\\0 (126).jpg': 'hockey_ball',\n",
       " 'pred\\\\0 (127).jpg': 'hockey_ball',\n",
       " 'pred\\\\0 (128).jpg': 'hockey_ball',\n",
       " 'pred\\\\0 (129).jpg': 'hockey_ball',\n",
       " 'pred\\\\0 (13).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (130).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (131).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (14).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (15).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (16).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (17).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (18).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (19).jpg': 'rugby_ball',\n",
       " 'pred\\\\0 (2).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (20).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (21).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (22).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (23).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (24).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (25).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (26).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (27).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (28).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (29).jpg': 'shuttlecock',\n",
       " 'pred\\\\0 (3).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (30).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (31).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (32).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (33).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (34).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (35).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (36).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (37).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (38).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (39).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (4).jpg': 'hockey_puck',\n",
       " 'pred\\\\0 (40).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (41).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (42).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (43).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (44).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (45).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (46).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (47).jpg': 'table_tennis_ball',\n",
       " 'pred\\\\0 (48).jpg': 'table_tennis_ball'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
